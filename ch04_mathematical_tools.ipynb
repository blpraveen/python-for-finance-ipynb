{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Mathematical Tools"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not only since the arrival of the so-called Rocket Scientists on Wall Street in the 80s and 90s has finance evolved into a discipline of applied mathematics. While early research papers in finance came by with a few mathematical expressions and equations, current ones are mainly comprised of mathematical expressions and equations with some explanatory text around."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This chapter introduces a number of useful mathematical tools for finance without providing a detailed background for each of them. There are many useful books on this topic available that is why this chapter focuses on how to use the respective tools and techniques with `Python` . Among others, the chapter presents:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<ul>\n",
      "<li>\n",
      "<p><strong>approximation</strong>: regression and interpolation are among the most often used numerical techniques in finance</p>\n",
      "</li>\n",
      "<li>\n",
      "<p><strong>convex optimization</strong>: a number of financial disciplines needs tools for convex optimization, e.g. option pricing when it comes to model calibration</p>\n",
      "</li>\n",
      "<li>\n",
      "<p><strong>integration</strong>: in particular the valuation of financial (derivative) assets often boils down to the evaluation of integrals</p>\n",
      "</li>\n",
      "<li>\n",
      "<p><strong>symbolic mathematics</strong>: <code>Python</code> provides with <code>SymPy</code> a powerful tool for symbolic mathematics, e.g. to solve (systems of) equations</p>\n",
      "</li>\n",
      "</ul>\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Approximation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To begin with, let us import the libraries that we need for the moment, i.e. `NumPy` and `matplotlib.pyplot` ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Throughout, the main example function is the following which is comprised of a trigonometric term and a linear term."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def f(x):\n",
      "   return np.sin(x) + 0.5 * x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The main focus is the approximation of this function over a given interval by _regression_ and _interpolation_. First, a plot of the function to have a better view on what exactly the approximation shall achieve. The interval of interest shall be $[-2 \\pi, 2 \\pi ]$. Figure\u00a04-1 displays the function over the given interval."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.linspace(-4 * np.pi, 4 * np.pi, 50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(x, f(x), 'b')\n",
      "plt.grid(True)\n",
      "plt.xlabel('x')\n",
      "plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "<matplotlib.text.Text at 0x2f0fe10>"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x2aa6d50>"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot\"><img src=\"files/images/sin_plot.png\" alt=\"sin plot\"><figcaption>Example function plot</figcaption></figure>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Regression"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Regression is a rather efficient tool when it comes to function approximation. It is not only suited to approximate one-dimensional functions but works well also in higher dimensions. The numerical techniques needed to come up with regression results are easily implemented and quickly executed. Basically, the task of regression, given a set of so-called basis functions $b\\_d, d \\in \\{1, \\dots, D\\}$, is to find optimal parameters $\\alpha\\_{1}^\\*,...,\\alpha\\_{D}^\\*$ according to Minimization problem of regression where $y\\_i \\equiv f(x\\_i)$ for $i \\in \\{1, \\dots, I\\}$ observation points. The $x\\_i$ are considered _independent_ observations and the $y\\_i$ _dependent_ observations (in a functional or statistical sense)."
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Monomials as Basis Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One of the most simple cases is to take monomials as basis function, i.e. $b_1 = 1, b_2 = x, b_3 = x^2, b_4 = x^3, \\dots$. In such a case, `NumPy` has built-in functions for both the determination of the optimal parameters, namely `polyfit` , as well as the evaluation of the approximation given a set of input values, namely `polyval` . In typical vectorized fashion, this takes on the form as follows for a linear regression, i.e. for `deg=1` ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [5]: reg = np.polyfit(x, f(x), deg=1)\n",
      "        ry = np.polyval(reg, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Given the regression estimates stored in the `ry` array, we can compare the regession result with the original function as presented in Figure\u00a04-2. Of course, a linear regression cannot account for the `sin` part of the example function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [6]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "        plt.plot(x, ry, 'r.', label='regression')\n",
      "        plt.legend(loc=0)\n",
      "        plt.grid(True)\n",
      "        plt.xlabel('x')\n",
      "        plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_1\"><img src=\"files/images/sin_plot_reg_1.png\" alt=\"sin plot reg 1\"><figcaption>Example function and linear regression</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To account for the `sin` part of the example function, higher order monomials are necessary. The next regession attempt takes monomials up to the order of 5 as basis function. It should not be too surprising that the regression result, as seen in Figure\u00a04-3 now looks much closer to the original function. However, it is still far away from being perfect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [7]: reg = np.polyfit(x, f(x), deg=5)\n",
      "        ry = np.polyval(reg, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [8]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "        plt.plot(x, ry, 'r.', label='regression')\n",
      "        plt.legend(loc=0)\n",
      "        plt.grid(True)\n",
      "        plt.xlabel('x')\n",
      "        plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_2\"><img src=\"files/images/sin_plot_reg_2.png\" alt=\"sin plot reg 2\"><figcaption>Regression with monomials up to order 5</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The last attempt now takes monomials up to order 7 to approximate the example function. In this case, the result as presented in Figure\u00a04-4 is quite convincing."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [9]: reg = np.polyfit(x, f(x), 7)\n",
      "        ry = np.polyval(reg, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [10]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "         plt.plot(x, ry, 'r.', label='regression')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_3\"><img src=\"files/images/sin_plot_reg_3.png\" alt=\"sin plot reg 3\"><figcaption>Regression with monomials up to order 7</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A brief check reveals that the result is not perfect."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [11]: np.allclose(f(x), ry)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[11]: False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, the Mean Squared Error (MSE) is not too large."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [12]: np.sum((f(x) - ry) ** 2) / len(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[12]: 0.0017769134759517658"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Individual Basis Functions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, you can reach better regression results when you can choose _better_ sets of basis function, e.g. by exploiting knowledge about the function to approximate. In this case, the individual basis functions have to be defined via a matrix approach, i.e. using a `NumPy` `ndarray` object. First, the case with monomials up to order 3."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [13]: matrix = np.zeros((3 + 1, len(x)))\n",
      "         matrix[3, :] = x ** 3\n",
      "         matrix[2, :] = x ** 2\n",
      "         matrix[1, :] = x\n",
      "         matrix[0, :] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The sub-library `numpy.linalg` provides the function `lstsq` to solve least-squares optimization problems as the one in Minimization problem of regression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [14]: reg = np.linalg.lstsq(matrix.T, f(x))[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Applying `lstsq` to our problem in this way, yields the optimal parameters for the single basis functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [15]: reg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[15]: array([  1.13968447e-14,   5.62777448e-01,  -8.88178420e-16,\n",
      "                 -5.43553615e-03])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get the regression estimates we apply the `dot` function to the `reg` and `matrix` arrays. Figure\u00a04-5 shows the result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [16]: ry = np.dot(reg, matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [17]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "         plt.plot(x, ry, 'r.', label='regression')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_4\"><img src=\"files/images/sin_plot_reg_4.png\" alt=\"sin plot reg 4\"><figcaption>Regression via least-squares function</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The result in Figure\u00a04-5 is not really good as expected based on our previous experience with monomials. Using the more general approach allows us to exploit our knowledge about the example function. We know that there is a `sin` part in the function. Therefore, it makes sense to include a sine function into the set of basis function. For simplicity, we replace the the highest order monomial."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [18]: matrix[3, :] = np.sin(x)\n",
      "         reg = np.linalg.lstsq(matrix.T, f(x))[0]\n",
      "         ry = np.dot(reg, matrix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure\u00a04-6 illustrates that the regession is now pretty close to the original function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [19]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "         plt.plot(x, ry, 'r.', label='regression')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_5\"><img src=\"files/images/sin_plot_reg_5.png\" alt=\"sin plot reg 5\"><figcaption>Regression using individual functions</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Indeed, the regression now is \u201cperfect\u201d in a numerical sense."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [20]: np.allclose(f(x), ry)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[20]: True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [21]: np.sum((f(x) - ry) ** 2) / len(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[21]: 2.2749084503102031e-31"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In fact, the minimization routine recovers the correct parameters of 1 for the `sin` part and 0.5 for the linear part."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [22]: reg"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[22]: array([  1.55428020e-16,   5.00000000e-01,   0.00000000e+00,\n",
      "                  1.00000000e+00])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Noisy Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Regression can cope equally well with _noisy_ data. Be it data from simulation or from (not-perfect) measurements, regression performs equally well in general. To illustrate this point, let us generate both independent observations with noise and also dependent observations with noise."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [23]: xn = np.linspace(-2 * np.pi, 2 * np.pi, 50)\n",
      "         xn = xn + 0.15 * np.random.standard_normal(len(xn))\n",
      "         yn = f(xn) + 0.25 * np.random.standard_normal(len(xn))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The very regression is the same."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [24]: reg = np.polyfit(xn, yn, 7)\n",
      "         ry = np.polyval(reg, xn)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure\u00a04-7 reveals that the regession results are closer to the original function than the noisy data points. In a sense, the regression averages out the noise to some extent."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [25]: plt.plot(xn, yn, 'b^', label='f(x)')\n",
      "         plt.plot(xn, ry, 'ro', label='regression')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_6\"><img src=\"files/images/sin_plot_reg_6.png\" alt=\"sin plot reg 6\"><figcaption>Regression with noisy data</figcaption></figure>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Unsorted Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another important aspect of regression is that the approach also works seamlessly with unsorted data. The previous examples all rely on sorted $x$ data. This does not have to be the case. To make the point, let us randomize the independent data points as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [26]: xu = np.random.rand(50) * 4 * np.pi - 2 * np.pi\n",
      "         yu = f(xu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In this case, you can hardly identify any structure by just visually inspecting the raw data."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [27]: print xu[:10].round(2)\n",
      "         print yu[:10].round(2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[27]: [-0.99 -3.72  0.64  1.05  3.53  1.97  6.24  2.69  2.61 -5.54]\n",
      "         [-1.33 -1.31  0.92  1.39  1.38  1.91  3.07  1.78  1.81 -2.09]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with the noisy data, the very regression approach does not care for the order of the observation points. This becomes obvious by inspecting the structure of the minimization problem in Minimization problem of regression. It becomes also obvious by the results as presented in Figure\u00a04-8."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [28]: reg = np.polyfit(xu, yu, 5)\n",
      "         ry = np.polyval(reg, xu)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [29]: plt.plot(xu, yu, 'b^', label='f(x)')\n",
      "         plt.plot(xu, ry, 'ro', label='regression')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_reg_7\"><img src=\"files/images/sin_plot_reg_7.png\" alt=\"sin plot reg 7\"><figcaption>Regression with unsorted data</figcaption></figure>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Multiple Dimensions"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another convenient characteristic of the least-squares regession approach is that it carries over to multiple dimensions without to many modifications. As an example function we take `fm` as presented next."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [30]: def fm((x, y)):\n",
      "             return np.sin(x) + 0.25 * x + np.sqrt(y) + 0.05 * y ** 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To visualize this function, we need a grid of (independent) data points."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [31]: x = np.linspace(0, 10, 20)\n",
      "         y = np.linspace(0, 10, 20)\n",
      "         X, Y = np.meshgrid(x, y)\n",
      "         Z = fm((X, Y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Based on the grid of inpendent and dependent data points as embodied now by `X, Y, Z` , Figure\u00a04-9 presents the shape of the function `fm` ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [32]: from mpl_toolkits.mplot3d import Axes3D\n",
      "\n",
      "         fig = plt.figure(figsize=(9, 6))\n",
      "         ax = fig.gca(projection='3d')\n",
      "         surf = ax.plot_surface(X, Y, Z, rstride=2, cstride=2, cmap=cm.coolwarm,\n",
      "                 linewidth=0.5, antialiased=True)\n",
      "         ax.set_xlabel('x')\n",
      "         ax.set_ylabel('y')\n",
      "         ax.set_zlabel('f(x, y)')\n",
      "         fig.colorbar(surf, shrink=0.5, aspect=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_3d_1\"><img src=\"files/images/sin_plot_3d_1.png\" alt=\"sin plot 3d 1\"><figcaption>Function with two parameters</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To get good regression results, we compile a set of basis functions, including both a `sin` and a `sqrt` function, which leverages our knowledge of the example function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [33]: matrix = np.zeros((len(x), 9 + 1))\n",
      "         matrix[:, 9] = x * y\n",
      "         matrix[:, 8] = np.sqrt(y)\n",
      "         matrix[:, 7] = np.sin(x)\n",
      "         matrix[:, 6] = x ** 3\n",
      "         matrix[:, 5] = y ** 3\n",
      "         matrix[:, 4] = x ** 2\n",
      "         matrix[:, 3] = y ** 2\n",
      "         matrix[:, 2] = x\n",
      "         matrix[:, 1] = y\n",
      "         matrix[:, 0] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `statsmodels` library offers the quite general and helpful function `OLS` for least-squares regression both in one dimension and multiple dimensions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [34]: import statsmodels.api as sm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [35]: model = sm.OLS(fm((x, y)), matrix).fit()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "One advantage of using the `OLS` function is that it provides a wealth of additional information about the regression and its quality."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [36]: model.summary()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[36]: <class 'statsmodels.iolib.summary.Summary'>\n",
      "         \"\"\"\n",
      "                                     OLS Regression Results\n",
      "\n",
      "         =======================================================================\n",
      "         =======\n",
      "         Dep. Variable:                      y   R-squared:\n",
      "           1.000\n",
      "         Model:                            OLS   Adj. R-squared:\n",
      "           1.000\n",
      "         Method:                 Least Squares   F-statistic:                 5.\n",
      "         866e+26\n",
      "         Date:                Thu, 02 Jan 2014   Prob (F-statistic):          1.\n",
      "         01e-183\n",
      "         Time:                        15:29:47   Log-Likelihood:\n",
      "          554.94\n",
      "         No. Observations:                  20   AIC:\n",
      "          -1098.\n",
      "         Df Residuals:                      14   BIC:\n",
      "          -1092.\n",
      "         Df Model:                           5\n",
      "\n",
      "         =======================================================================\n",
      "         =======\n",
      "                          coef    std err          t      P>|t|      [95.0% Conf\n",
      "         . Int.]\n",
      "         -----------------------------------------------------------------------\n",
      "         -------\n",
      "         const      -2.812e-14   2.57e-13     -0.109      0.914     -5.79e-13  5\n",
      "         .23e-13\n",
      "         x1             0.1250   4.21e-13   2.97e+11      0.000         0.125\n",
      "           0.125\n",
      "         x2             0.1250   4.21e-13   2.97e+11      0.000         0.125\n",
      "           0.125\n",
      "         x3             0.0167   3.63e-14   4.59e+11      0.000         0.017\n",
      "           0.017\n",
      "         x4             0.0167   3.63e-14   4.59e+11      0.000         0.017\n",
      "           0.017\n",
      "         x5         -5.447e-16   2.85e-15     -0.191      0.851     -6.66e-15  5\n",
      "         .57e-15\n",
      "         x6          4.588e-16   2.85e-15      0.161      0.875     -5.66e-15  6\n",
      "         .58e-15\n",
      "         x7             1.0000   1.29e-13   7.76e+12      0.000         1.000\n",
      "           1.000\n",
      "         x8             1.0000   1.04e-12   9.64e+11      0.000         1.000\n",
      "           1.000\n",
      "         x9             0.0167   3.63e-14   4.59e+11      0.000         0.017\n",
      "           0.017\n",
      "         =======================================================================\n",
      "         =======\n",
      "         Omnibus:                        2.653   Durbin-Watson:\n",
      "           0.014\n",
      "         Prob(Omnibus):                  0.265   Jarque-Bera (JB):\n",
      "           2.176\n",
      "         Skew:                           0.721   Prob(JB):\n",
      "           0.337\n",
      "         Kurtosis:                       2.270   Cond. No.\n",
      "             nan\n",
      "         =======================================================================\n",
      "         =======\n",
      "\n",
      "         Warnings:\n",
      "         [1] The smallest eigenvalue is -2.48e-11. This might indicate that ther\n",
      "         e are\n",
      "         strong multicollinearity problems or that the design matrix is singular.\n",
      "         \"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [37]: a = model.params\n",
      "         a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[37]: array([ -2.81163981e-14,   1.25000000e-01,   1.25000000e-01,\n",
      "                  1.66666667e-02,   1.66666667e-02,  -5.44703171e-16,\n",
      "                  4.58834359e-16,   1.00000000e+00,   1.00000000e+00,\n",
      "                  1.66666667e-02])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The function `reg_func` gives back, for the given optimal regression parameters and the indpendent data points, the function values for the regression function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [38]: def reg_func(a, (x, y)):\n",
      "             f9 = a[9] * x * y\n",
      "             f8 = a[8] * np.sqrt(y)\n",
      "             f7 = a[7] * np.sin(x)\n",
      "             f6 = a[6] * x ** 3\n",
      "             f5 = a[5] * y ** 3\n",
      "             f4 = a[4] * x ** 2\n",
      "             f3 = a[3] * y ** 2\n",
      "             f2 = a[2] * x\n",
      "             f1 = a[1] * y\n",
      "             f0 = a[0] * 1\n",
      "             return (f9 + f8 + f7 + f6 + f5 +\n",
      "                      f4 + f3 + f2 + f1 + f0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These values can then be compared with the original shape of the example function as shown in Figure\u00a04-10"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [39]: RZ = reg_func(a, (X, Y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [40]: fig = plt.figure(figsize=(9, 6))\n",
      "         ax = fig.gca(projection='3d')\n",
      "         surf1 = ax.plot_surface(X, Y, Z, rstride=2, cstride=2, cmap=cm.coolwarm,\n",
      "                 linewidth=0.5, antialiased=True)\n",
      "         surf2 = ax.plot_wireframe(X, Y, RZ, rstride=2, cstride=2, label='regression')\n",
      "         ax.set_xlabel('x')\n",
      "         ax.set_ylabel('y')\n",
      "         ax.set_zlabel('f(x, y)')\n",
      "         ax.legend()\n",
      "         fig.colorbar(surf, shrink=0.5, aspect=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_3d_2\"><img src=\"files/images/sin_plot_3d_2.png\" alt=\"sin plot 3d 2\"><figcaption>Higher dimension regression</figcaption></figure>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Interpolation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Compared to regression, _interpolation_, e.g. with cubic splines, is much more involved mathematically than regression. It is also limited to low-dimensional problems. Given an ordered set ob observation points (ordered in the $x$ dimension), the basic idea is do a regression between two neighboring data points in a way that not only the data point is perfectly matched by the resulting, piece-wise defined interpolation function but that this function is also continuously differentiable at the data points. This requires at least interpolation of degree 3, i.e. with cubic splines. However, the approach also works with quadratic and even linear splines. First, the import of the respective sub-library."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [41]: import scipy.interpolate as spi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [42]: x = np.linspace(-2 * np.pi, 2 * np.pi, 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We take again the original example function for illustration purposes."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [43]: def f(x):\n",
      "             return np.sin(x) + 0.5 * x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The application itself, given an $x$-ordered set of data points, is as simple as the application of `polyfit` and `polyval` . Here, the respective functions are `splrep` and `splev` ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [44]: ipo = spi.splrep(x, f(x), k=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [45]: iy = spi.splev(x, ipo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As Figure\u00a04-11 shows, the interpolation seems already really good with linear splines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [46]: plt.plot(x, f(x), 'b', label='f(x)')\n",
      "         plt.plot(x, iy, 'r.', label='interpolation')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_ipo_1\"><img src=\"files/images/sin_plot_ipo_1.png\" alt=\"sin plot ipo 1\"><figcaption>Example plot with linear interpolation</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This can be confirmed numerically."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [47]: np.allclose(f(x), iy)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[47]: True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Splines interpolation is often used in finance to generate estimates for dependent values of independent data points not included in the original observations. To this end, let us pick a much smaller interval and have a closer look of the interpolated values with the linear splines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [48]: xd = np.linspace(1.0, 3.0, 50)\n",
      "         iyd = spi.splev(xd, ipo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure\u00a04-12 reveals that the interpolation function indeed interpolates _linearly_ between two observation points. For certain application this might be not precise enough. In addition, it is evident that the function is not continuously differentiable at the original data points; another drawback."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [49]: plt.plot(xd, f(xd), 'b', label='f(x)')\n",
      "         plt.plot(xd, iyd, 'r.', label='interpolation')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_ipo_2\"><img src=\"files/images/sin_plot_ipo_2.png\" alt=\"sin plot ipo 2\"><figcaption>Example plot (detail) with linear interpolation</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Therefore, let us repeat the complete exercise, this time using cubic splines."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [50]: ipo = spi.splrep(x, f(x), k=3)\n",
      "         iyd = spi.splev(xd, ipo)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, the detailed sub-interval shows a graphically perfect interpolation (see Figure\u00a04-13)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [51]: plt.plot(xd, f(xd), 'b', label='f(x)')\n",
      "         plt.plot(xd, iyd, 'r.', label='interpolation')\n",
      "         plt.legend(loc=0)\n",
      "         plt.grid(True)\n",
      "         plt.xlabel('x')\n",
      "         plt.ylabel('f(x)')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_plot_ipo_3\"><img src=\"files/images/sin_plot_ipo_3.png\" alt=\"sin plot ipo 3\"><figcaption>Example plot (detail) with cubic splines interpolation</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Numerically, the interpolation is not perfect, but the MSE is really small."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [52]: np.allclose(f(xd), iyd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[52]: False"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [53]: np.sum((f(xd) - iyd) ** 2) / len(xd)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[53]: 1.1349319851436255e-08"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Convex Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In finance and economics, convex optimization plays an important role. Examples are the calibration of option pricing models to market data or the optimization of an agent\u2019s utility. As an example function, wich we want to minimize, we take `fm` as defined in the following."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [54]: def fm((x, y)):\n",
      "             return (np.sin(x) + 0.05 * x ** 2\n",
      "                   + np.sin(y) + 0.05 * y ** 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [55]: x = np.linspace(-10, 10, 50)\n",
      "         y = np.linspace(-10, 10, 50)\n",
      "         X, Y = np.meshgrid(x, y)\n",
      "         Z = fm((X, Y))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure\u00a04-14 shows the function graphically for the above defined intervals for $x$ and $y$. Visual inspection already reveals that this function has at least multiple local minima. The existence of a global minimum cannot really confirmed by this graphical representation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [56]: fig = plt.figure(figsize=(9, 6))\n",
      "         ax = fig.gca(projection='3d')\n",
      "         surf = ax.plot_surface(X, Y, Z, rstride=2, cstride=2, cmap=cm.coolwarm,\n",
      "                 linewidth=0.5, antialiased=True)\n",
      "         ax.set_xlabel('x')\n",
      "         ax.set_ylabel('y')\n",
      "         ax.set_zlabel('f(x, y)')\n",
      "         fig.colorbar(surf, shrink=0.5, aspect=5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"opt_plot_3d\"><img src=\"files/images/opt_plot_3d.png\" alt=\"opt plot 3d\"><figcaption>Function to minimize with two parameters</figcaption></figure>"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In what follows, we want to implement both a _global_ minimization approach as well as a _local_ one. The functions `brute` and `fmin` which we want to use can be found in the sub-library `scipy.optimize`"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [57]: import scipy.optimize as spo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Global Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "To have a closer look behind the scenes when we initiate the minimization procedures, we amend the original function by a an option to output current parameter values as well as the function value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [58]: def fo((x, y)):\n",
      "             z = np.sin(x) + 0.05 * x ** 2 + np.sin(y) + 0.05 * y ** 2\n",
      "             if output == True:\n",
      "                 print '%8.4f %8.4f %8.4f' % (x, y, z)\n",
      "             return z"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This allows us to keep track of all relevant information for the procedure as the following code with the respective output illustrates. `brute` takes parameter ranges as input. For example, providing parameter range `(-10, 10.1, 5)` for the $x$ value will lead to \u201ctested\u201d values of `-10, -5, 0, 5, 10` ."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [59]: output = True\n",
      "         spo.brute(fo, ((-10, 10.1, 5), (-10, 10.1, 5)), finish=None)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[59]: -10.0000 -10.0000  11.0880\n",
      "         -10.0000 -10.0000  11.0880\n",
      "         -10.0000  -5.0000   7.7529\n",
      "         -10.0000   0.0000   5.5440\n",
      "         -10.0000   5.0000   5.8351\n",
      "         -10.0000  10.0000  10.0000\n",
      "          -5.0000 -10.0000   7.7529\n",
      "          -5.0000  -5.0000   4.4178\n",
      "          -5.0000   0.0000   2.2089\n",
      "          -5.0000   5.0000   2.5000\n",
      "          -5.0000  10.0000   6.6649\n",
      "           0.0000 -10.0000   5.5440\n",
      "           0.0000  -5.0000   2.2089\n",
      "           0.0000   0.0000   0.0000\n",
      "           0.0000   5.0000   0.2911\n",
      "           0.0000  10.0000   4.4560\n",
      "           5.0000 -10.0000   5.8351\n",
      "           5.0000  -5.0000   2.5000\n",
      "           5.0000   0.0000   0.2911\n",
      "           5.0000   5.0000   0.5822\n",
      "           5.0000  10.0000   4.7471\n",
      "          10.0000 -10.0000  10.0000\n",
      "          10.0000  -5.0000   6.6649\n",
      "          10.0000   0.0000   4.4560\n",
      "          10.0000   5.0000   4.7471\n",
      "          10.0000  10.0000   8.9120\n",
      "\n",
      "Out[59]: array([ 0.,  0.])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The optimal parameter values, given the initial parametrization of the function, are $x=y=0$. The resulting function value is also 0 as a quick review of the above output reveals. The first parametrization above is quite rough in that we used steps of width 5 for both input parameters. This can of course be refined considerably, leading to better results in this case."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [60]: output = False\n",
      "         opt1 = spo.brute(fo, ((-10, 10.1, 0.1), (-10, 10.1, 0.1)), finish=None)\n",
      "         opt1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[60]: array([-1.4, -1.4])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [61]: fm(opt1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[61]: -1.7748994599769203"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The optimal parameter values are now $x=y=-1.4$ and the minimal function value for the global minimization is about -1.7749."
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Local Optimization"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the local convex optimization we want to draw on the results from the global optimization. The function `fmin` takes at the minimum the function to minize and the starting parameter values as input. In addition, you can define level for the input parameter tolerance as well as the function value tolerance and also for the maximium number of iterations and function calls."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [62]: output = True\n",
      "         opt2 = spo.fmin(fo, opt1, xtol=0.001, ftol=0.001, maxiter=15, maxfun=20)\n",
      "         opt2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[62]:  -1.4000  -1.4000  -1.7749\n",
      "          -1.4700  -1.4000  -1.7743\n",
      "          -1.4000  -1.4700  -1.7743\n",
      "          -1.3300  -1.4700  -1.7696\n",
      "          -1.4350  -1.4175  -1.7756\n",
      "          -1.4350  -1.3475  -1.7722\n",
      "          -1.4088  -1.4394  -1.7755\n",
      "          -1.4438  -1.4569  -1.7751\n",
      "          -1.4328  -1.4427  -1.7756\n",
      "          -1.4591  -1.4208  -1.7752\n",
      "          -1.4213  -1.4347  -1.7757\n",
      "          -1.4235  -1.4096  -1.7755\n",
      "          -1.4305  -1.4344  -1.7757\n",
      "          -1.4168  -1.4516  -1.7753\n",
      "          -1.4305  -1.4260  -1.7757\n",
      "          -1.4396  -1.4257  -1.7756\n",
      "          -1.4259  -1.4325  -1.7757\n",
      "          -1.4259  -1.4241  -1.7757\n",
      "          -1.4304  -1.4177  -1.7757\n",
      "          -1.4270  -1.4288  -1.7757\n",
      "         Warning: Maximum number of function evaluations has been exceeded.\n",
      "\n",
      "Out[62]: array([-1.42702972, -1.42876755])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we can observe a refinement of the solution and a somewhat lower function value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [63]: fm(opt2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[63]: -1.7757246992239009"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For many convex optimization problems it is advisable to have a global minimization before the local one. The major reason for this is that local convex optimization algorithms can be easily trapped in a local minimum, ignoring \u201cbetter\u201d local minima and/or a global minimum at all. The following shows that setting the starting parametrization to $x=y=2$ gives a \u201cminimum\u201d value of above zero."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [64]: output = False\n",
      "         spo.fmin(fo, (2.0, 2.0), maxiter=250)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[64]: Optimization terminated successfully.\n",
      "                  Current function value: 0.015826\n",
      "                  Iterations: 46\n",
      "                  Function evaluations: 86\n",
      "\n",
      "Out[64]: array([ 4.2710728 ,  4.27106945])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Integration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Especially when it comes to valuation and optin pricing, integration is an important mathematical tools. This stems from the fact that risk-neutral values of derivatives can be expressed in general as the discounted _expectation_ of their payoff under the risk-neutral (martingale) measure. The expectation in turn is a sum in the discrete case and an integral in the continuous case. The sub-library `scipy-integrate` provides function for numerical integration."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [65]: import scipy.integrate as sci"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, we stick to the example function comprised of a `sin` component and a linear one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [66]: def f(x):\n",
      "             return np.sin(x) + 0.5 * x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are interested in the integral over the interval $\\[0.5, 9.5]$, i.e. the integral as in Integral of example function."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Figure\u00a04-15 provides a graphical representation of the integral with $f(x) \\equiv \\sin(x) + 0.5 x$"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [67]: a = 0.5  # left integral limit\n",
      "         b = 9.5  # right integral limit\n",
      "         x = np.linspace(0, 10)\n",
      "         y = f(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [68]: from matplotlib.patches import Polygon\n",
      "\n",
      "         fig, ax = plt.subplots(figsize=(7, 5))\n",
      "         plt.plot(x, y, 'b', linewidth=2)\n",
      "         plt.ylim(ymin=0)\n",
      "\n",
      "         # area under the function\n",
      "         # between lower and upper limit\n",
      "         Ix = np.linspace(a, b)\n",
      "         Iy = f(Ix)\n",
      "         verts = [(a, 0)] + list(zip(Ix, Iy)) + [(b, 0)]\n",
      "         poly = Polygon(verts, facecolor='0.7', edgecolor='0.5')\n",
      "         ax.add_patch(poly)\n",
      "\n",
      "         # labels\n",
      "         plt.text(0.75 * (a + b), 1.5, r\"$\\int_a^b f(x)dx$\",\n",
      "                  horizontalalignment='center', fontsize=20)\n",
      "\n",
      "         plt.figtext(0.9, 0.075, '$x$')\n",
      "         plt.figtext(0.075, 0.9, '$f(x)$')\n",
      "\n",
      "         ax.set_xticks((a, b))\n",
      "         ax.set_xticklabels(('$a$', '$b$'))\n",
      "         ax.set_yticks([f(a), f(b)])\n",
      "         ax.set_yticklabels(('$f(a)$', '$f(b)$'))\n",
      "         plt.grid(True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<figure id=\"sin_integral\"><img src=\"files/images/sin_integral.png\" alt=\"sin integral\"><figcaption>Example function with integral area</figcaption></figure>"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Numerical Integration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The `integrate` sub-library provides a selection of functions to numerically integration a given mathematical function and the upper and lower integration limits. Examples are `fixed_quad` for _fixed Gaussian quadrature_, `quad` for _adaptive quadrature_ and `romberg` for _Romberg integration_."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [69]: sci.fixed_quad(f, a, b)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[69]: 24.366995967084588"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [70]: sci.quad(f, a, b)[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[70]: 24.374754718086752"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [71]: sci.romberg(f, a, b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[71]: 24.374754718086713"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "There is also a number of integration function that take as input already `list` or `ndarray` objects with function values and input values. Examples here are `trapz` using the _trapzoidal_ rule and `simps` implementint _Simpson\u2019s_ rule."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [72]: xi = np.linspace(0.5, 9.5, 25)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [73]: sci.trapz(f(xi), xi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[73]: 24.352733271544526"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [74]: sci.simps(f(xi), xi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[74]: 24.374964184550748"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Integration by Simulation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The valuation of options and derivatives by Monte Carlo simulation (cf. ) rests on the insight that you can evaluate an integral by simulation. To this end draw $I$ random values of $x$ between the integral limits and evaluate the integration function at every random value of $x$. Sum up all the function values and take the average to arrive at an average function value over the integration interval. Multiply this value by the length of the integration interval."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The following code shows how the Monte Carlo estimated integral value converges to the real one when one increases the number of random draws. The estimator is already quite close for really small numbers of random draws."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [75]: for i in range(1, 20):\n",
      "             np.random.seed(1000)\n",
      "             x = np.random.random(i * 10) * (b - a) + a\n",
      "             print np.sum(f(x)) / len(x) * (b - a)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[75]: 24.8047622793\n",
      "         26.5229188983\n",
      "         26.2655475192\n",
      "         26.0277033994\n",
      "         24.9995418144\n",
      "         23.8818101416\n",
      "         23.5279122748\n",
      "         23.507857659\n",
      "         23.6723674607\n",
      "         23.6794104161\n",
      "         24.4244017079\n",
      "         24.2390053468\n",
      "         24.115396925\n",
      "         24.4241919876\n",
      "         23.9249330805\n",
      "         24.1948421203\n",
      "         24.1173483782\n",
      "         24.1006909297\n",
      "         23.7690510985"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Symbolic Computation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The previous sections are mainly concerned with numerical computation. This section now introduces symbolic computation which can be applied beneficially in many areas of finance. To this end, let us import `sympy` , the library specifically dedicated to symbolic computation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [76]: import sympy as sy"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Basics"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`SymPy` introduces new classes of objects. A fundamental class is the `Symbol` class."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [77]: x = sy.Symbol('x')\n",
      "         y = sy.Symbol('y')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [78]: type(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[78]: sympy.core.symbol.Symbol"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with `NumPy` , `SymPy` has a number of (mathemtatical) function definitions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [79]: sy.sqrt(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[79]: sqrt(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This already illustrates a major difference. Although `x` has no numerical value, the square root of `x` is nevertheless defined with `SymPy` since `x` is a `Symbol` object. In that sense, `sy.sqrt(x)` can be part of arbitrary mathematical expressions. Notice that `SymPy` automatically simplifies the expression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [80]: 3 + sy.sqrt(x) - 4 ** 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[80]: sqrt(x) - 13"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Similary, you can define arbitrary functions using `Symbol` objects. They are not to be confused with `Python` functions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [81]: f = x ** 2 + 3 + 0.5 * x ** 2 + 3 / 2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [82]: sy.simplify(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[82]: 1.5*x**2 + 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`SymPy` provides three basic renderers for mathematical expressions:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<ul>\n",
      "<li>\n",
      "<p><code>Latex</code>-based</p>\n",
      "</li>\n",
      "<li>\n",
      "<p><code>Unicode</code>-based</p>\n",
      "</li>\n",
      "<li>\n",
      "<p><code>Ascii</code>-based</p>\n",
      "</li>\n",
      "</ul>\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When working for example solely in the `IPython` `Notebook` , `Latex` rendering is generally a good, i.e. visually appealing, choice. In what follows, we restrain to the most simple option, `Ascii` , to illustrate that there no hand-made type setting involved."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [83]: sy.init_printing(pretty_print=False, use_unicode=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [84]: print sy.pretty(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[84]:      2\n",
      "         1.5*x  + 4"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As you can see from the ouput, multiple lines are used whenever needed. Also, for example, for the visual representation of the square root function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [85]: print sy.pretty(sy.sqrt(x) + 0.5)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[85]:   ___\n",
      "         \\/ x  + 0.5"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can not go into details here, but `SymPy` also provides many other useful mathematical functions, for example, when it comes to numerically evaluating $\\pi$. The following shows the first 40 characters of the `string` representation of $\\pi$ up to the 50,000th digit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [86]: pi_str = str(sy.N(sy.pi, 400000))\n",
      "         pi_str[:40]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[86]: '3.14159265358979323846264338327950288419'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And here the last 40 digits of the first 400,000."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [87]: pi_str[-40:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[87]: '8245672736856312185020980470362464176198'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You can also look up you birthday if you wish. However, no guarantee for a hit."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [88]: pi_str.find('111272')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[88]: 366713"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Equations"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A strength of `SymPy` is solving equations, e.g. of the form $x^2-1=0$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [89]: sy.solve(x ** 2 - 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[89]: [-1, 1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In general, `SymPy` presumes that you are looking for solution equating the expression given to zero. Therefore, equations like $x^2-1=3$ might have to be reformulated to get the desired result."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [90]: sy.solve(x ** 2 - 1 - 3)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[90]: [-2, 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Of course, `SymPy` can cope with more complex expressions like $x^3 + 0.5 x^2 -1=0$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [91]: sy.solve(x ** 3 + 0.5 * x ** 2 - 1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[91]: [-0.679047164748276 - 0.839206763026694*I, -0.679047164748276 + 0.83920\n",
      "         6763026694*I, 0.858094329496553 - 0.e-22*I]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "However, there is obviously no guarantee for a solution, neither from a mathematical point of view (i.e. existence of a soluation) nor from an algorithmic point of view (i.e. implementation)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "`SymPy` works similarly with functions exhibiting more than one input parameter and to this end also with complex numbers. As a simple example take the equation $x^2 + y^2=0$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [92]: sy.solve(x ** 2 + y ** 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[92]: [{x: -I*y}, {x: I*y}]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Integration"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Another strength of `SymPy` is integration and differentiation. In what follows, we revisit the example function used for numerical and simulation-based integration and derive now both a _symbolic_ and a _numerically_ exact solution. We need symbols for the integration limits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [93]: a, b = sy.symbols('a b')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Having defined the new symbols, we can \u201cpretty print\u201d the symbolic integral."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [94]: print sy.pretty(sy.Integral(sy.sin(x) + 0.5 * x, (x, a, b)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[94]:   b\n",
      "           /\n",
      "          |\n",
      "          |  (0.5*x + sin(x)) dx\n",
      "          |\n",
      "         /\n",
      "         a"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using `integrate` , we can derive the _antiderivative_ of the integration function."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [95]: int_func = sy.integrate(sy.sin(x) + 0.5 * x, x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [96]: print sy.pretty(int_func)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[96]:       2\n",
      "         0.25*x  - cos(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Equipped with the antiderivative, the numerical evaluation of the integral is only three steps away. To numerically evaluation a `SymPy` expression replace the respective symbol by the numerical value, using the method `subs` and call the method `evalf` on the new expression."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [97]: Fb = int_func.subs(x, 9.5).evalf()\n",
      "         Fa = int_func.subs(x, 0.5).evalf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The difference between `Fb` and `Fa` then yields the exact integral value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [98]: Fb - Fa  # exact value of integral"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[98]: 24.3747547180867"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The integral can also be solved symbolically with the symbolic integration limits."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [99]: int_func_limits = sy.integrate(sy.sin(x) + 0.5 * x, (x, a, b))\n",
      "         print(sy.pretty(int_func_limits))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[99]:         2         2\n",
      "         - 0.25*a  + 0.25*b  + cos(a) - cos(b)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As before, numerical substitution and evaluation then yields the integral value."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [100]: int_func_limits.subs({a : 0.5, b : 9.5}).evalf()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[100]: 24.3747547180868"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Finally, providing numerical integration limits yields the exact value in a single step."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [101]: sy.integrate(sy.sin(x) + 0.5 * x, (x, 0.5, 9.5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[101]: 24.3747547180867"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Differentiation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The derivative of the antiderivative shall yield in general the original function. Let us check this briefly by applying the `diff` function to the symbolic antiderivative from before."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [102]: int_func.diff()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[102]: 0.5*x + sin(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As with the integration example, we want to use differentiation now to derive the exact solution of the convex minimization problem from above. To this end, define the respective function symbolically as follows."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [103]: f = (sy.sin(x) + 0.05 * x ** 2\n",
      "             + sy.sin(y) + 0.05 * y ** 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For the minimization, we need the two partial derivatives with respect to both $x$ and $y$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [104]: del_x = sy.diff(f, x)\n",
      "          del_x"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[104]: 0.1*x + cos(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [105]: del_y = sy.diff(f, y)\n",
      "          del_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[105]: 0.1*y + cos(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "A necessary but not sufficient condition for a global minimum is that both partial derivatives are zero. As stated before, there is no guarantee for a symbolic solution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [106]: sy.solve(del_x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[106]: NotImplementedError\n",
      "          multiple generators [x, cos(x)]\n",
      "          No algorithms are implemented to solve equation x/10 + cos(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Both algorithmic and (multiple) existence issues come into play here. However, we can solve the two equations numerically, providing \u201ceducated\u201d guesses based on the global and local minimization efforts from before."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [107]: xo = sy.nsolve(del_x, -1.5)\n",
      "          xo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[107]: mpf('-1.4275517787645941')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [108]: yo = sy.nsolve(del_y, -1.5)\n",
      "          yo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[108]: mpf('-1.4275517787645941')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [109]: f.subs({x : xo, y : yo}).evalf()\n",
      "            # global minimum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[109]: -1.77572565314742"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Again, providing uneducated/arbitrary guesses might trap the algorithm in a local minimum instead of the global one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [110]: xo = sy.nsolve(del_x, 1.5)\n",
      "          xo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[110]: mpf('1.7463292822528528')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [111]: yo = sy.nsolve(del_y, 1.5)\n",
      "          yo"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[111]: mpf('1.7463292822528528')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "In [112]: f.subs({x : xo, y : yo}).evalf()\n",
      "            # local minimum"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Out[112]: 2.27423381055640"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This numerically illustrates that zero partial derivatives are necessary but not sufficient."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}