{
  "metadata": {
    "name": "Statistics"
  },
  "nbformat": 3,
  "nbformat_minor": 0,
  "worksheets": [
    {
      "cells": [
        {
          "cell_type": "heading",
          "level": 1,
          "metadata": {
          },
          "source": "Statistics"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Statistics itself is a vast field as of today. The tools and results the field provides have become indispensible for finance. This also explains the popularity of domain specific languages like `R` in the finance industry. The more elobarate and complex statistical models become, the more important it is to have available easy-to-use and high performing computational solutions."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "A single chapter in a book like this one cannot do justice to the richness and the broadness of the statistics field. Therefore, the approach — as in many other chapters — is to focus on selected topics that seem of paramount importance or that are suited to provide a good starting point when it comes to the use of `Python` for the particular tasks at hand. The chapter has three major focal points:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ul>\n<li>\n<p><strong>normality tests</strong>: a large number of important financial models, like the mean-variance portfolio theory or the capital asset pricing model (CAPM) rest on the assumption that returns of securities are normally distributed; therefore, this chapter presents some approaches to test a given time series for normality of returns</p>\n</li>\n<li>\n<p><strong>portfolio theory</strong>: modern portfolio theory (MPT) can considered to be one of the early and biggest successes of statistics in finance; it somehow took over the lead, starting in the early 1950s by the works of pioneer Harry Markowitz, in replacing people’s judgement and experience by rigorous mathematical and statistical methods when it comes to the investment of money in financial markets</p>\n</li>\n<li>\n<p><strong>Bayesian regression</strong>: on a fundamental level, Bayesian statistics introduces the notion of <em>beliefs</em> of agents and the <em>updating of beliefs</em> to statistics; when it comes to linear regression, for example, this might take on the form of having a statistical distribution for regression parameters instead of single point estimates (for the intercept and slope of the regression line); nowadays, Bayesian methods are rather popular and important in finance, that is why we illustrate some (advanced) applications in this chapter</p>\n</li>\n</ul>\n"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Normality Tests"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The _normal distribution_ can be considered the most important distribution in finance and one of the major statistical building blocks of financial theory. Among others, the following cornerstones of financial theory rest to a large extent on the normal distribution of stock market returns:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ul>\n<li>\n<p><strong>portfolio theory</strong>: when stock returns are normally distributed, optimal portfolio choice can be casted into a setting where only the <em>mean return</em> and the <em>variance of the returns</em> (volatility) as well as the <em>covariances</em> between different stocks are relevant for an investment decision, i.e. an optimal portfolio composition</p>\n</li>\n<li>\n<p><strong>capital asset pricing model</strong>: again, when stock returns are normally distributed, prices of single stocks can be elegantly expressed in relationship to a broad market index; the relationship is generally expressed by a measure for the co-movement of a single stock with the market index called beta (<span data-type=\"tex\">$\\beta$</span>)</p>\n</li>\n<li>\n<p><strong>efficient markets hypothesis</strong>: an <em>efficient</em> market is a market where prices reflect all available information, where “all” can be defined more narrowly or more widely (e.g. as in “all publicly available” information); if this hypothesis holds true then stock prices fluctuate randomly and returns are normally distributed</p>\n</li>\n<li>\n<p><strong>option pricing theory</strong>: Brownian motion is <em>the</em> standard and benchmark model for the modeling of random stock price movements (and for other securities); the famous Black-Scholes-Merton option pricing formula uses a geometric Brownian motion as the model for the a stock’s random fluctuations over time, leading to normally distributed returns</p>\n</li>\n</ul>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This by far non-exhaustive list underpins the importance of the normality assumption in finance."
        },
        {
          "cell_type": "heading",
          "level": 3,
          "metadata": {
          },
          "source": "Benchmark Case"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "To set the stage for the further analyses, we start the geometric Brownian motion as one of the canonical stochastic processes used in financial modeling. The following can be said about the characteristics of paths from a geometric Brownian motion latexmath[$S$]:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ul>\n<li>\n<p><strong>normal log-returns</strong>: log-returns latexmath[$\\log \\frac{S_t}{S_s} = \\log S_t - \\log S_s$] between two times <span data-type=\"tex\">$0&lt;s&lt;t$</span> are normally distributed</p>\n</li>\n<li>\n<p><strong>log-normal values</strong>: at any time <span data-type=\"tex\">$t&gt;0$</span> the values latexmath[$S_t$] are log-normally distributed</p>\n</li>\n</ul>\n"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "For what follows, we need a number of `Python` libraries. In particular `scipy.stats` (cf. [http://docs.scipy.org/doc/scipy/reference/stats.html)](http://docs.scipy.org/doc/scipy/reference/stats.html)) and the `statsmodels.api` (cf. [http://statsmodels.sourceforge.net/stable/)](http://statsmodels.sourceforge.net/stable/))."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [1]: import numpy as np\n        import scipy.stats as scs\n        import statsmodels.api as sm\n        import matplotlib as mpl\n        import matplotlib.pyplot as plt\n        %matplotlib inline",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Let us define a function to generate Monte Carlo paths for the geometric Brownian motion (see [???](ch04.html#stochastics))."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [2]: def gen_paths(S0, r, sigma, T, M, I):\n            ''' Generate Monte Carlo paths for geometric Brownian motion.\n\n            Parameters\n            ==========\n            S0 : float\n                initial stock/index value\n            r : float\n                constant short rate\n            sigma : float\n                constant volatility\n            T : float\n                final time horizon\n            M : int\n                number of time steps/intervals\n            I : int\n                number of paths to be simulated\n\n            Returns\n            =======\n            paths : ndarray, shape (M + 1, I)\n                simulated paths given the parameters\n            '''\n            dt = float(T) / M\n            paths = np.zeros((M + 1, I), np.float64)\n            paths[0] = S0\n            for t in range(1, M + 1):\n                rand = np.random.standard_normal(I)\n                rand = (rand - rand.mean()) / rand.std()\n                paths[t] = paths[t - 1] * np.exp((r - 0.5 * sigma ** 2) * dt +\n                                                 sigma * np.sqrt(dt) * rand)\n            return paths",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The following is a possible parametrization for the Monte Carlo simulation, generating, in combination with function `gen_paths` , 50,000 paths with 50 time steps."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [3]: S0 = 100.\n        r = 0.05\n        sigma = 0.2\n        T = 1.0\n        M = 50\n        I = 250000",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [4]: paths = gen_paths(S0, r, sigma, T, M, I)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-1 shows the first ten simulated paths from the simulation."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [5]: plt.plot(paths[:, :10])\n        plt.grid(True)\n        plt.xlabel('time steps')\n        plt.ylabel('index level')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"normal_sim_1\"><img src=\"files/images/normal_sim_1.png\" alt=\"normal sim 1\"><figcaption>10 simulated paths of geometric Brownian motion</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Our main interest is in the distribution of the log-returns. The following code generates a `ndarray` object with all log-returns."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [6]: log_returns = np.log(paths[1:] / paths[0:-1])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Consider the very first simulated path over the 50 time steps."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [7]: paths[:, 0]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[7]: array([ 100.        ,  104.49613442,  112.61940211,  114.39160989,\n                114.84522119,  115.3460347 ,  118.48322203,  115.76676034,\n                117.07674029,  119.74287952,  121.77408994,  117.9172147 ,\n                114.87930486,  113.67261057,  114.27867871,  113.89426613,\n                111.65084595,  108.26986852,  110.58780901,  110.64535184,\n                106.27497502,  109.75503353,  112.16576925,  113.22403873,\n                113.12825474,  116.04506065,  106.84453178,  109.66710139,\n                108.87490158,  109.99068424,  110.50740102,  111.83952328,\n                113.85314169,  119.36019184,  124.42968434,  125.52693883,\n                127.09973856,  123.36206316,  129.70924503,  129.08670348,\n                130.43663771,  126.23305548,  124.63749481,  128.04156594,\n                124.38510225,  123.84204179,  121.42755482,  122.5528474 ,\n                122.15343102,  121.53937305,  123.04277465])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "A log-return series for a simulated path might then takes the form:"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [8]: log_returns[:, 0]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[8]: array([ 0.04397989,  0.07486393,  0.01561373,  0.00395758,  0.00435129,\n                0.02683476, -0.02319388,  0.01125214,  0.02251715,  0.01682083,\n               -0.0321848 , -0.02610075, -0.01055957,  0.00531754, -0.00336949,\n               -0.01989397, -0.03074966,  0.02118296,  0.0005202 , -0.04030022,\n                0.03222108,  0.02172695,  0.00939064, -0.00084633,  0.0254564 ,\n               -0.08260377,  0.02607462, -0.00724989,  0.01019614,  0.00468682,\n                0.01198252,  0.01784437,  0.04723636,  0.04159503,  0.00877962,\n                0.01245173, -0.02984849,  0.05017173, -0.00481107,  0.01040328,\n               -0.03275773, -0.01272036,  0.02694546, -0.02897253, -0.00437552,\n               -0.01968907,  0.00922452, -0.00326446, -0.00503962,  0.01229379])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This is something one might maybe experience in financial markets as well: days when you make a _positive return_ on your investment and other days when you are _losing money_ relative to your most recent wealth position."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The function `print_statistics` is a wrapper function for the `describe` function from the `scipy.stats` sub-library. It mainly generates a better (human) readable output for such statistics as the mean, the skewness or the kurtosis of a given (historical or simulated) data set."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [9]: def print_statistics(array):\n            ''' Prints selected statistics.\n\n            Parameters\n            ==========\n            array: ndarray\n                object to generate statistics on\n            '''\n            sta = scs.describe(array)\n            print \"%14s %15s\" % ('statistic', 'value')\n            print 30 * \"-\"\n            print \"%14s %15.5f\" % ('size', sta[0])\n            print \"%14s %15.5f\" % ('min', sta[1][0])\n            print \"%14s %15.5f\" % ('max', sta[1][1])\n            print \"%14s %15.5f\" % ('mean', sta[2])\n            print \"%14s %15.5f\" % ('std', np.sqrt(sta[3]))\n            print \"%14s %15.5f\" % ('skew', sta[4])\n            print \"%14s %15.5f\" % ('kurtosis', sta[5])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "For example, the following shows the function in action, using a flattened version of the `ndarray` object containing the log-returns."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [10]: print_statistics(log_returns.flatten())",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[10]:      statistic           value\n         ------------------------------\n                   size  12500000.00000\n                    min        -0.15271\n                    max         0.14698\n                   mean         0.00060\n                    std         0.02828\n                   skew        -0.00011\n               kurtosis         0.00057",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The data set in this case consists of 2,550,000 data points with the values mainly lying between +/- 0.135. We would expect annualized values for the mean return of 0.05 and the standard deviation (volatility) of 0.2. The annualized values of the data set come close to these values, even if not matching them perfectly (multiply the mean value by 50 and the standard deviation by $\\sqrt{50}$)."
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-2 compares the frequency distribution of the simulated log-returns with the probability density function (pdf) of the normal distribution given the parametrizations for `r` and `sigma` . The function used is `norm.pdf` from the `scipy.stats` sub-library. There is obviously quite a good fit."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [11]: plt.hist(log_returns.flatten(), bins=70, normed=True)\n         plt.grid(True)\n         plt.xlabel('log-return')\n         plt.ylabel('frequency')\n         x = np.linspace(plt.axis()[0], plt.axis()[1])\n         plt.plot(x, scs.norm.pdf(x, loc=r / M, scale=sigma / np.sqrt(M)),\n                  'r', lw=2.0)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"normal_sim_2\"><img src=\"files/images/normal_sim_2.png\" alt=\"normal sim 2\"><figcaption>Histogram of log-returns and normal density function</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Comparing a frequency distribution (histogram) with a theoretical pdf is not the only way to graphically “test” for normality. So-called _quantile-quantile plots_ (qq plots) are also well suited for this task. Here, sample quantile values are compared to theoretical quantile values. For normally distributed sample data sets, such a plot might look as in Figure 6-3: the absolute majority of the quantile values (dots) lying on a straight line."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [12]: sm.qqplot(log_returns.flatten()[::500], line='s')\n         plt.grid(True)\n         plt.xlabel('theoretical quantiles')\n         plt.ylabel('sample quantiles')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"sim_val_qq_1\"><img src=\"files/images/sim_val_qq_1.png\" alt=\"sim val qq 1\"><figcaption>Quantile-quantile plot for log returns</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "However appealing the graphical approaches might be, they generally cannot replace more rigorous testing procedures. The function `normality_tests` combines three different statistical tests:"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<ul>\n<li>\n<p><strong>skewness test</strong> (<code>skewtest</code>): this tests whether the skew of the sample data is “normal”, i.e. has a value close enough to zero</p>\n</li>\n<li>\n<p><strong>kurtosis test</strong> (<code>kurtosistest</code>): similarly, this tests whether the kurtosis of the sample data is “normal”, again close enough to zero</p>\n</li>\n<li>\n<p><strong>normality test</strong> (<code>normaltest</code>): this combines the other two test approaches to test for normality</p>\n</li>\n</ul>\n"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [13]: def normality_tests(array):\n             ''' Tests for normality distribution of given data set.\n\n             Parameters\n             ==========\n             array: ndarray\n                 object to generate statistics on\n             '''\n             print \"Skew of data set  %14.3f\" % scs.skew(array)\n             print \"Skew test p-value %14.3f\" % scs.skewtest(array)[1]\n             print \"Kurt of data set  %14.3f\" % scs.kurtosis(array)\n             print \"Kurt test p-value %14.3f\" % scs.kurtosistest(array)[1]\n             print \"Norm test p-value %14.3f\" % scs.normaltest(array)[1]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The test values indicate that the log-returns are indeed normally distributed, i.e. they show p-values of 0.05 or above."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [14]: normality_tests(log_returns.flatten())",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[14]: Skew of data set          -0.000\n         Skew test p-value          0.877\nOut[14]: Kurt of data set           0.001\nOut[14]: Kurt test p-value          0.678\nOut[14]: Norm test p-value          0.907",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Finally, let us check whether the end-of-period values are indeed log-normally distributed. This boils down to a normality test as well since we only have to transform the data by applying the log function to it (to then arrive at normally distributed data — or maybe not). Figure 6-4 plots both the log-normally distributed end-of-period values and the transformed ones (“log index level”)."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [15]: f, (ax1, ax2) = plt.subplots(1, 2, figsize=(9, 4))\n         ax1.hist(paths[-1], bins=30)\n         ax1.grid(True)\n         ax1.set_xlabel('index level')\n         ax1.set_ylabel('frequency')\n         ax1.set_title('regular data')\n         ax2.hist(np.log(paths[-1]), bins=30)\n         ax2.grid(True)\n         ax2.set_xlabel('log index level')\n         ax2.set_title('log data')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"normal_sim_3\"><img src=\"files/images/normal_sim_3.png\" alt=\"normal sim 3\"><figcaption>Histogram of simulated end-of-period index levels</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The statistics for the data set show expected behaviour: for example, a mean value close to 105 and a standard deviation (volatility) close to 20%."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [16]: print_statistics(paths[-1])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[16]:      statistic           value\n         ------------------------------\n                   size    250000.00000\n                    min        41.43758\n                    max       258.58353\n                   mean       105.12132\n                    std        21.21754\n                   skew         0.62308\n               kurtosis         0.70505",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The log index level values also have skew and kurtosis close to zero."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [17]: print_statistics(np.log(paths[-1]))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[17]:      statistic           value\n         ------------------------------\n                   size    250000.00000\n                    min         3.72419\n                    max         5.55522\n                   mean         4.63517\n                    std         0.19968\n                   skew         0.00658\n               kurtosis         0.00857",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "This data set also shows high p-values providing strong support for the normal distribution hypothesis."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [18]: normality_tests(np.log(paths[-1]))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[18]: Skew of data set           0.007\n         Skew test p-value          0.179\n         Kurt of data set           0.009\nOut[18]: Kurt test p-value          0.380\n         Norm test p-value          0.276",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-5 compares again the frequency distribution with the pdf of the normal distribution — showing a pretty good fit (as now is of course to be expected)."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [19]: log_data = np.log(paths[-1])\n         plt.hist(log_data, bins=70, normed=True)\n         plt.grid(True)\n         plt.xlabel('index levels')\n         plt.ylabel('frequency')\n         x = np.linspace(plt.axis()[0], plt.axis()[1])\n         plt.plot(x, scs.norm.pdf(x, log_data.mean(), log_data.std()),\n                  'r', lw=2.0)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"normal_sim_4\"><img src=\"files/images/normal_sim_4.png\" alt=\"normal sim 4\"><figcaption>Histogram of log index levels and normal density function</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-6 also supports the hypothesis that the log index levels are normally distributed."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [20]: sm.qqplot(log_data, line='s')\n         plt.grid(True)\n         plt.xlabel('theoretical quantiles')\n         plt.ylabel('sample quantiles')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"sim_val_qq_2\"><img src=\"files/images/sim_val_qq_2.png\" alt=\"sim val qq 2\"><figcaption>Quantile-quantile plot for log index levels</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 3,
          "metadata": {
          },
          "source": "Real World Data"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "We are now very well equipped to attack real world data and see how the normality assumption does beyond the financial laboratory. We are going to analyze four historical time series, for two stock indices (German DAX index and the American S&P 500 index) as well as for two stocks (Apple Inc. and Google Inc.). The data tool of choice is `pandas` (cf. ???)."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [21]: import pandas as pd\n         import pandas.io.data as pdd",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Here the symbols for the time series we are interested in. The curious reader might of course replace these by any other symbol of interest."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [22]: symbols = ['^GDAXI', '^GSPC', 'AAPL', 'GOOG']",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The following reads only the `Close` time series data into a single `DataFrame` object for all symbols."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [23]: data = pd.DataFrame()\n         for sym in symbols:\n             data[sym] = pdd.DataReader(sym, data_source='yahoo',\n                                     start='1/1/2006')['Close']\n         data = data.dropna()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [24]: data.info()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[24]: <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 2048 entries, 2006-01-03 00:00:00 to 2014-03-19 00:00:00\n         Data columns (total 4 columns):\n         ^GDAXI    2048 non-null float64\n         ^GSPC     2048 non-null float64\n         AAPL      2048 non-null float64\n         GOOG      2048 non-null float64\n         dtypes: float64(4)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The four time series start at rather different absolute values."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [25]: data.head()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[25]:              ^GDAXI    ^GSPC   AAPL    GOOG\n         Date\n         2006-01-03  5460.68  1268.80  74.75  435.23\n         2006-01-04  5523.62  1273.46  74.97  445.24\n         2006-01-05  5516.53  1273.48  74.38  451.24\n         2006-01-06  5536.32  1285.45  76.30  465.66\n         2006-01-09  5537.11  1290.15  76.05  466.90\n\n         [5 rows x 4 columns]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-7 shows therefore the four time series in direct comparison but normalized to starting value of 100."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [26]: (data / data.ix[0] * 100).plot(figsize=(8, 4))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"real_returns_1\"><img src=\"files/images/real_returns_1.png\" alt=\"real returns 1\"><figcaption>Evolution of stock and index levels over time</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Calculating the log-returns with `pandas` is a bit more convenient than with `NumPy` since we can use the `shift` method."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [27]: log_returns = np.log(data / data.shift(1))\n         log_returns.head()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[27]:               ^GDAXI     ^GSPC      AAPL      GOOG\n         Date\n         2006-01-03       NaN       NaN       NaN       NaN\n         2006-01-04  0.011460  0.003666  0.002939  0.022739\n         2006-01-05 -0.001284  0.000016 -0.007901  0.013386\n         2006-01-06  0.003581  0.009356  0.025486  0.031456\n         2006-01-09  0.000143  0.003650 -0.003282  0.002659\n\n         [5 rows x 4 columns]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Figure 6-8 provides all log-returns in the form of histograms. Although not easy to judge, one can guess that these frequency distributions might not be normal."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [28]: log_returns.hist(bins=50, figsize=(9, 6))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"real_returns_2\"><img src=\"files/images/real_returns_2.png\" alt=\"real returns 2\"><figcaption>Histogram of respective log-returns</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "As a next step, consider the different statistics for the time series data sets. Especially the kurtosis values seem to be far from normal for all four data sets."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [29]: for sym in symbols:\n             print \"\\nResults for Symbol %s\" % sym\n             print 30 * \"-\"\n             log_data = np.array(log_returns[sym].dropna())\n             print_statistics(log_data)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[29]: Results for Symbol ^GDAXI\n         ------------------------------\n              statistic           value\n         ------------------------------\n                   size      2047.00000\n                    min        -0.07739\n                    max         0.10797\n                   mean         0.00026\n                    std         0.01493\n                   skew         0.03168\n               kurtosis         6.29464\n\n         Results for Symbol ^GSPC\n         ------------------------------\n              statistic           value\n         ------------------------------\n                   size      2047.00000\n                    min        -0.09470\n                    max         0.10957\n                   mean         0.00019\n                    std         0.01395\n                   skew        -0.30802\n               kurtosis         9.54712\n\n         Results for Symbol AAPL\n         ------------------------------\n              statistic           value\n         ------------------------------\n                   size      2047.00000\n                    min        -0.19747\n                    max         0.13019\n                   mean         0.00096\n                    std         0.02286\n                   skew        -0.31641\n               kurtosis         5.68347\n\n         Results for Symbol GOOG\n         ------------------------------\n              statistic           value\n         ------------------------------\n                   size      2047.00000\n                    min        -0.12340\n                    max         0.18225\n                   mean         0.00050\n                    std         0.02019\n                   skew         0.36543\n               kurtosis         9.27664",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "We pick two symbols to inspect the data via a qq plot. Figure 6-9 shows the qq plot for the S&P 500. Obviously the sample quantile values do not lie on a straight line indicating “non-normality”. For example, both on the left side and on the right side there are many values that lie well below the line and well above the line, respectively. This indicates that the time series data exhibits _fat tails_. Fat tails refer to a (frequency) distribution where negative and positive outliers are far more often observed than a normal distribution would imply."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [30]: sm.qqplot(log_returns['^GSPC'].dropna(), line='s')\n         plt.grid(True)\n         plt.xlabel('theoretical quantiles')\n         plt.ylabel('sample quantiles')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"real_val_qq_1\"><img src=\"files/images/real_val_qq_1.png\" alt=\"real val qq 1\"><figcaption>Quantile-quantile plot for S&amp;P 500 log returns</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "The same conclusions can be drawn from Figure 6-10 presenting the data for the Google Inc. stock. There also seems to be strong evidence for a fat tailed distribution."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [31]: sm.qqplot(log_returns['GOOG'].dropna(), line='s')\n         plt.grid(True)\n         plt.xlabel('theoretical quantiles')\n         plt.ylabel('sample quantiles')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"real_val_qq_2\"><img src=\"files/images/real_val_qq_2.png\" alt=\"real val qq 2\"><figcaption>Quantile-quantile plot for S&amp;P 500 log returns</figcaption></figure>"
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "All this leads us finally to the formal normality tests."
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [32]: for sym in symbols:\n             print \"\\nResults for Symbol %s\" % sym\n             print 32 * \"-\"\n             log_data = np.array(log_returns[sym].dropna())\n             normality_tests(log_data)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[32]: Results for Symbol ^GDAXI\n         --------------------------------\n         Skew of data set           0.032\n         Skew test p-value          0.557\n         Kurt of data set           6.295\n         Kurt test p-value          0.000\n         Norm test p-value          0.000\n\n         Results for Symbol ^GSPC\n         --------------------------------\n         Skew of data set          -0.308\n         Skew test p-value          0.000\n         Kurt of data set           9.547\n         Kurt test p-value          0.000\n         Norm test p-value          0.000\n\n         Results for Symbol AAPL\n         --------------------------------\n         Skew of data set          -0.316\n         Skew test p-value          0.000\n         Kurt of data set           5.683\n         Kurt test p-value          0.000\n         Norm test p-value          0.000\n\n         Results for Symbol GOOG\n         --------------------------------\n         Skew of data set           0.365\n         Skew test p-value          0.000\n         Kurt of data set           9.277\n         Kurt test p-value          0.000\n         Norm test p-value          0.000",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "Throughout, p-values of the different tests are all zero, _strongly rejecting the test hypothesis_ that the different sample data sets are normally distributed. This shows that the normal assumption for stock market returns — as for example embodied in the geometric Brownian motion model — cannot be justified in general and that one might have to use richer models generating fat tails (e.g. jump diffision models or models with stochastic volatility)."
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Portfolio Optimization"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [33]: import numpy as np\n         import pandas as pd\n         import pandas.io.data as web\n         import matplotlib.pyplot as plt\n         %matplotlib inline",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [34]: symbols = ['AAPL', 'GOOG', 'MSFT', 'DB', 'DAI.DE', 'GLD']\n         noa = len(symbols)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [35]: data = pd.DataFrame()\n         for sym in symbols:\n             data[sym] = web.DataReader(sym, data_source='yahoo')['Close']\n         data.columns = symbols",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [36]: (data / data.ix[0]).plot(figsize=(8, 4))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"portfolio_1\"><img src=\"files/images/portfolio_1.png\" alt=\"portfolio 1\"><figcaption>Stock prices over time</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [37]: rets = np.log(data / data.shift(1))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [38]: rets.mean() * 252",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[38]: AAPL      0.216565\n         GOOG      0.154559\n         MSFT      0.056709\n         DB       -0.117523\n         DAI.DE    0.121214\n         GLD       0.036698\n         dtype: float64",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [39]: rets.cov() * 252",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[39]:             AAPL      GOOG      MSFT        DB    DAI.DE       GLD\n         AAPL    0.076611  0.029925  0.022015  0.045026  0.024978  0.005982\n         GOOG    0.029925  0.064602  0.024264  0.050225  0.028982  0.000925\n         MSFT    0.022015  0.024264  0.052388  0.050909  0.028856  0.002655\n         DB      0.045026  0.050225  0.050909  0.193948  0.071871  0.009774\n         DAI.DE  0.024978  0.028982  0.028856  0.071871  0.103172  0.005285\n         GLD     0.005982  0.000925  0.002655  0.009774  0.005285  0.034490\n\n         [6 rows x 6 columns]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [40]: weights = np.random.random(noa)\n         weights /= np.sum(weights)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [41]: weights",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[41]: array([ 0.15788442,  0.14204263,  0.00879702,  0.17295025,  0.26707045,\n                 0.25125524])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [42]: np.sum(rets.mean() * weights) * 252",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[42]: 0.077912662513977535",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [43]: np.dot(weights.T, np.dot(rets.cov() * 252, weights))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[43]: 0.038291796169390879",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [44]: np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[44]: 0.19568289697720359",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [45]: prets = []\n         pvars = []\n         for p in range (1000):\n             weights = np.random.random(noa)\n             weights /= np.sum(weights)\n             prets.append(np.sum(rets.mean() * weights) * 252)\n             pvars.append(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))\n         prets = np.array(prets)\n         pvars = np.array(pvars)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [46]: plt.figure(figsize=(8, 4))\n         plt.scatter(np.sqrt(pvars), prets, c=prets / np.sqrt(pvars), marker='o')\n         plt.grid(True)\n         plt.xlabel('expected volatility')\n         plt.ylabel('expected return')\n         plt.colorbar(label='Sharpe ratio')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"portfolio_2\"><img src=\"files/images/portfolio_2.png\" alt=\"portfolio 2\"><figcaption>Expected return and volatility for different/random portfolio weights</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [47]: def statistics(weights):\n             pret = np.sum(rets.mean() * weights) * 252\n             pvol = np.sqrt(np.dot(weights.T, np.dot(rets.cov() * 252, weights)))\n             return np.array([pret, pvol, pret / pvol])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [48]: import scipy.optimize as sco",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [49]: def min_func_sharpe(weights):\n             return -statistics(weights)[2]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [50]: cons = ({'type': 'eq', 'fun': lambda x:  np.sum(x) - 1})",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [51]: bnds = tuple((0, 1) for x in range(noa))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [52]: opts = sco.minimize(min_func_sharpe, noa * [1. / noa,], method='SLSQP',\n                                bounds=bnds, constraints=cons)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [53]: opts",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[53]:   status: 0\n          success: True\n             njev: 7\n             nfev: 56\n              fun: -0.85112015073355451\n                x: array([  5.11118729e-01,   2.87934416e-01,   1.16876994e-16,\n                 -7.22837588e-16,   6.00776165e-02,   1.40869238e-01])\n          message: 'Optimization terminated successfully.'\n              jac: array([ -3.50847840e-05,  -2.75522470e-05,   1.58443704e-01,\n                  1.54369477e+00,   6.38067722e-05,   1.56424940e-04,\n                  0.00000000e+00])\n              nit: 7",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [54]: opts['x'].round(3)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[54]: array([ 0.511,  0.288,  0.   , -0.   ,  0.06 ,  0.141])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [55]: statistics(opts['x']).round(3)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[55]: array([ 0.168,  0.197,  0.851])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [56]: def min_func_variance(weights):\n             return statistics(weights)[1] ** 2",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [57]: optv = sco.minimize(min_func_variance, noa * [1. / noa,], method='SLSQP',\n                                bounds=bnds, constraints=cons)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [58]: optv",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[58]:   status: 0\n          success: True\n             njev: 8\n             nfev: 64\n              fun: 0.019161474149871269\n                x: array([  7.66645749e-02,   1.52828800e-01,   2.15115272e-01,\n                 -6.50521303e-18,   3.83738933e-02,   5.17017460e-01])\n          message: 'Optimization terminated successfully.'\n              jac: array([ 0.0384672 ,  0.0379545 ,  0.03829067,  0.05978071,  0\n         .03848651,\n                 0.03841176,  0.        ])\n              nit: 8",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [59]: optv['x'].round(3)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[59]: array([ 0.077,  0.153,  0.215, -0.   ,  0.038,  0.517])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [60]: statistics(optv['x']).round(3)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[60]: array([ 0.076,  0.138,  0.549])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [61]: cons = ({'type': 'eq', 'fun': lambda x:  statistics(x)[0] - tret},\n                 {'type': 'eq', 'fun': lambda x:  np.sum(x) - 1})",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [62]: bnds = tuple((0, 1) for x in weights)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [63]: def min_func(weights):\n             return statistics(weights)[1]",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [64]: %%time\n         trets = np.linspace(0.0, 0.20, 30)\n         tvars = []\n         for tret in trets:\n             cons = ({'type': 'eq', 'fun': lambda x:  statistics(x)[0] - tret},\n                     {'type': 'eq', 'fun': lambda x:  np.sum(x) - 1})\n             res = sco.minimize(min_func, noa * [1. / noa,], method='SLSQP',\n                                bounds=bnds, constraints=cons)\n             # print res\n             tvars.append(res['fun'])\n         tvars = np.array(tvars)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[64]: CPU times: user 2.79 s, sys: 7.91 ms, total: 2.79 s\n         Wall time: 2.81 s",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [65]: plt.figure(figsize=(8, 4))\n         plt.scatter(np.sqrt(pvars), prets,\n                     c=prets / np.sqrt(pvars), marker='o')\n         plt.scatter(tvars, trets,\n                     c=trets / np.sqrt(tvars), marker='x')\n         plt.plot(statistics(optv['x'])[1], statistics(optv['x'])[0],\n                  'r*', markersize=15.0)\n         plt.grid(True)\n         plt.xlabel('expected volatility')\n         plt.ylabel('expected return')\n         plt.colorbar(label='Sharpe ratio')",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"portfolio_3\"><img src=\"files/images/portfolio_3.png\" alt=\"portfolio 3\"><figcaption>Efficient frontier for the given assets</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 2,
          "metadata": {
          },
          "source": "Bayesian Regression"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [66]: # git clone git://github.com/Theano/Theano.git\n         # sudo python Theano/python.py install\n         # .bash_profile:: export DYLD_FALLBACK_LIBRARY_PATH=\n         #      $DYLD_FALLBACK_LIBRARY_PATH:/Library/anaconda/lib:",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [67]: # git clone https://github.com/pymc-devs/pymc.git\n         # sudo python pymc/setup.py install",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [68]: import pymc as pm",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "heading",
          "level": 3,
          "metadata": {
          },
          "source": "Introductory Example"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [69]: x = np.linspace(0, 10, 50)\n         y = 4 + 2 * x + np.random.standard_normal(len(x)) * 2",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [70]: with pm.Model() as model:\n                 # model specifications in PyMC3\n                 # are wrapped in a with-statement\n             # define priors\n             alpha = pm.Normal('alpha', mu=0, sd=20)\n             beta = pm.Normal('beta', mu=0, sd=20)\n             sigma = pm.Uniform('sigma', lower=0, upper=20)\n\n             # define linear regression\n             y_est = alpha + beta * x\n\n             # define likelihood\n             likelihood = pm.Normal('y', mu=y_est, sd=sigma, observed=y)\n\n             # inference\n             start = pm.find_MAP() # find starting value by optimization\n             step = pm.NUTS(state=start) # instantiate MCMC sampling algorithm\n             trace = pm.sample(100, step, start=start, progressbar=False)\n               # draw 100 posterior samples using NUTS sampling",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[70]: /Library/anaconda/lib/python2.7/site-packages/Theano-0.6.0-py2.7.egg/th\n         eano/gof/cmodule.py:284: RuntimeWarning: numpy.ndarray size changed, ma\n         y indicate binary incompatibility\n           rval = __import__(module_name, {}, {}, [module_name])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [71]: fig = pm.traceplot(trace, lines={'alpha': 4, 'beta': 2, 'sigma': 2})\n         plt.figure(figsize=(8, 8))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"pm_fig_1\"><img src=\"files/images/pm_fig_1.png\" alt=\"pm fig 1\"><figcaption>Trace plots for alpha, beta and sigma</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [72]: plt.figure(figsize=(8, 4))\n         plt.scatter(x, y, c=y, marker='v')\n         plt.colorbar()\n         plt.grid(True)\n         plt.xlabel('x')\n         plt.ylabel('y')\n         for i in range(10):\n             plt.plot(x, trace['alpha'][i] + trace['beta'][i] * x)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"pm_fig_2\"><img src=\"files/images/pm_fig_2.png\" alt=\"pm fig 2\"><figcaption>Sample data and 10 linear regression lines</figcaption></figure>"
        },
        {
          "cell_type": "heading",
          "level": 3,
          "metadata": {
          },
          "source": "Real Data"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [73]: # pip install zipline\n         # or: https://pypi.python.org/pypi/zipline",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [74]: import zipline\n         import pytz\n         import datetime as dt",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [75]: data = zipline.data.load_from_yahoo(stocks=['GLD', 'GDX'],\n                  end=dt.datetime(2013, 8, 1, 0, 0, 0, 0, pytz.utc)).dropna()\n         data.info()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[75]: GLD\n         GDX\n         <class 'pandas.core.frame.DataFrame'>\n         DatetimeIndex: 1811 entries, 2006-05-23 00:00:00+00:00 to 2013-08-01 00\n         :00:00+00:00\n         Data columns (total 2 columns):\n         GDX    1811 non-null float64\n         GLD    1811 non-null float64\n         dtypes: float64(2)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [76]: data.plot(figsize=(8, 4))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"zip_fig_1\"><img src=\"files/images/zip_fig_1.png\" alt=\"zip fig 1\"><figcaption>Co-movements of traiding pair</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [77]: data.index",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[77]: <class 'pandas.tseries.index.DatetimeIndex'>\n         [2006-05-23, ..., 2013-08-01]\n         Length: 1811, Freq: None, Timezone: UTC",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [78]: mpl_dates = mpl.dates.date2num(data.index)\n         mpl_dates",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[78]: array([ 732454.,  732455.,  732456., ...,  735079.,  735080.,  735081.])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [79]: plt.figure(figsize=(8, 4))\n         plt.scatter(data['GDX'], data['GLD'], c=mpl_dates, marker='o')\n         plt.grid(True)\n         plt.xlabel('GDX')\n         plt.ylabel('GLD')\n         plt.colorbar(ticks=mpl.dates.DayLocator(interval=250),\n                      format=mpl.dates.DateFormatter('%d %b %y'))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"zip_fig_2\"><img src=\"files/images/zip_fig_2.png\" alt=\"zip fig 2\"><figcaption>Scatter plot of prices</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [80]: with pm.Model() as model_reg:\n             alpha = pm.Normal('alpha', mu=0, sd=20)\n             beta = pm.Normal('beta', mu=0, sd=20)\n             sigma = pm.Uniform('sigma', lower=0, upper=20)\n\n             y_est = alpha + beta * data['GDX'].values\n\n             likelihood = pm.Normal('GLD', mu=y_est, sd=sigma, observed=data['GLD'].values)\n\n             start = pm.find_MAP()\n             step = pm.NUTS(state=start)\n             trace = pm.sample(100, step, start=start, progressbar=False)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [81]: plt.figure(figsize=(8, 4))\n         plt.scatter(data['GDX'], data['GLD'], c=mpl_dates, marker='o')\n         plt.grid(True)\n         plt.xlabel('GDX')\n         plt.ylabel('GLD')\n         for i in range(10):\n             plt.plot(data['GDX'], trace['alpha'][i] + trace['beta'][i] * data['GDX'])\n         plt.colorbar(ticks=mpl.dates.DayLocator(interval=250),\n                      format=mpl.dates.DateFormatter('%d %b %y'))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"pm_fig_3\"><img src=\"files/images/pm_fig_3.png\" alt=\"pm fig 3\"><figcaption>Scatter plot with “simple” regression lines</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [82]: model_randomwalk = pm.Model()\n         with model_randomwalk:\n             # std of random walk, best sampled in log space\n             sigma_alpha, log_sigma_alpha = model_randomwalk.TransformedVar(\n                                     'sigma_alpha',\n                                     pm.Exponential.dist(1. / .02, testval=.1),\n                                     pm.logtransform\n             )\n             sigma_beta, log_sigma_beta = model_randomwalk.TransformedVar(\n                                     'sigma_beta',\n                                     pm.Exponential.dist(1. / .02, testval=.1),\n                                     pm.logtransform\n             )",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [83]: from pymc.distributions.timeseries import GaussianRandomWalk\n         # to make the model more simple, we will apply the same coefficient\n         # to 50 data points at a time\n         subsample_alpha = 50\n         subsample_beta = 50\n\n         with model_randomwalk:\n             alpha = GaussianRandomWalk('alpha', sigma_alpha**-2,\n                                        shape=len(data) / subsample_alpha)\n             beta = GaussianRandomWalk('beta', sigma_beta**-2,\n                                       shape=len(data) / subsample_beta)\n\n             # make coefficients have the same length as prices\n             alpha_r = np.repeat(alpha, subsample_alpha)\n             beta_r = np.repeat(beta, subsample_beta)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [84]: len(data.dropna().GDX.values)  # a bit longer than 1,800",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[84]: 1811",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [85]: with model_randomwalk:\n             # define regression\n             regression = alpha_r + beta_r * data.GDX.values[:1800]\n\n             # assume prices are normally distributed,\n             # the mean comes from the regression\n             sd = pm.Uniform('sd', 0, 20)\n             likelihood = pm.Normal('y',\n                                    mu=regression,\n                                    sd=sd,\n                                    observed=data.GLD.values[:1800])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [86]: import scipy.optimize as sco\n         with model_randomwalk:\n             # first optimize random walk\n             start = pm.find_MAP(vars=[alpha, beta], fmin=sco.fmin_l_bfgs_b)\n\n             # sampling\n             step = pm.NUTS(scaling=start)\n             trace_rw = pm.sample(500, step, start=start, progressbar=False)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [87]: np.mean(trace_rw['alpha'], axis=0)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[87]: array([ 34.13169598,  34.31712363,  35.23012008,  36.5193268 ,\n                 37.87502796,  38.99617029,  40.48861673,  42.73011487,\n                 44.7716855 ,  46.61763511,  49.00180725,  51.6505585 ,\n                 53.34303588,  54.28275126,  56.04143477,  56.67413684,\n                 57.28317592,  58.4996924 ,  60.42617638,  61.33330864,\n                 63.05230098,  64.31152223,  66.76790533,  68.68683206,\n                 70.69907972,  73.007142  ,  74.664273  ,  76.87044082,\n                 79.56602072,  83.89228863,  85.23758667,  85.96988316,\n                 86.05372082,  84.7432198 ,  82.58441528,  79.30954078])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [88]: np.shape(trace_rw['alpha'])",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "Out[88]: (500, 36)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [89]: part_dates = np.linspace(min(mpl_dates), max(mpl_dates), 36)",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [90]: fig, ax1 = plt.subplots(figsize=(10, 5))\n         plt.plot(part_dates, np.mean(trace_rw['alpha'], axis=0),\n                  'b', lw=1.5, label='alpha')\n         plt.xlabel('date')\n         plt.ylabel('alpha')\n         plt.axis('tight')\n         plt.grid(True)\n         plt.legend(loc=2)\n         ax1.xaxis.set_major_formatter(mpl.dates.DateFormatter('%d %b %y') )\n         ax2 = ax1.twinx()\n         plt.plot(part_dates, np.mean(trace_rw['beta'], axis=0),\n                  'r', lw=1.5, label='beta')\n         plt.ylabel('beta')\n         plt.legend(loc=4)\n         fig.autofmt_xdate()",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"pm_fig_4\"><img src=\"files/images/pm_fig_4.png\" alt=\"pm fig 4\"><figcaption>Evolution of mean alpha and beta over time (updated estimates)</figcaption></figure>"
        },
        {
          "cell_type": "code",
          "collapsed": false,
          "input": "In [91]: plt.figure(figsize=(10, 5))\n         plt.scatter(data['GDX'], data['GLD'], c=mpl_dates, marker='o')\n         plt.colorbar(ticks=mpl.dates.DayLocator(interval=250),\n                      format=mpl.dates.DateFormatter('%d %b %y'))\n         plt.grid(True)\n         plt.xlabel('GDX')\n         plt.ylabel('GLD')\n         x = np.linspace(min(data['GDX']), max(data['GDX']))\n         for i in range(36):\n             alpha_rw = np.mean(trace_rw['alpha'].T[i])\n             beta_rw = np.mean(trace_rw['beta'].T[i])\n             plt.plot(x, alpha_rw + beta_rw * x, color=plt.cm.jet(256 * i / 36))",
          "language": "python",
          "metadata": {
          },
          "outputs": [

          ]
        },
        {
          "cell_type": "markdown",
          "metadata": {
          },
          "source": "<figure id=\"pm_fig_5\"><img src=\"files/images/pm_fig_5.png\" alt=\"pm fig 5\"><figcaption>Scatter plot with time-dependent regression lines (updated estimates)</figcaption></figure>"
        }
      ],
      "metadata": {
      }
    }
  ]
}